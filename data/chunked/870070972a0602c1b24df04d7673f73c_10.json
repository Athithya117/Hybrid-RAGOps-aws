{
  "document_id": "870070972a0602c1b24df04d7673f73c",
  "chunk_id": "870070972a0602c1b24df04d7673f73c_10",
  "chunk_type": "txt_subchunk",
  "text": "Beam/diversity hyperparameters:\n\n* Beam size B, path length L, and diversity constant gamma control exploration/exploitation tradeoffs. The authors found diversity helps recall and reduces redundant expansions.\n\nScoring:\n\n* Authors use a scoring function that combines dense embedding similarity and path scoring; alternatives include NLI-based scores or richer feature combinations.\n\nCost tradeoffs:\n\n* SyncGE increases offline storage and computation for triple extraction and indexing but saves online LLM tokens and iterations. This tradeoff is appealing when online LLM query costs or latency dominate.\n\nPractical tips:\n\n* Precompute triple neighbors and adjacency lists for fast graph expansion.\n* Cache frequent triple-to-passage mappings.\n* Use approximate nearest neighbor indices for path scoring to scale to large triple graphs.\n\n---\n\n## CLOSING SUMMARY\n\nGeAR is a practically motivated, empirically strong system that shows graph-based retrieval (with LLM-guided seeding and diverse triple beam search) can significantly improve multi-hop retrieval and QA while reducing LLM token usage. The approach trades increased offline indexing and triple resources for online efficiency gains, and the authors provide a clear pipeline, pseudocode, and experimental evidence across multiple benchmarks.\n\n---\n\n## END OF FILE",
  "token_count": 252,
  "embedding": null,
  "file_type": "text/plain",
  "source_url": "s3://e2e-rag-system-42/data/raw/txts/GeAR.txt",
  "page_number": null,
  "slide_range": null,
  "row_range": null,
  "token_range": null,
  "audio_range": null,
  "timestamp": "2025-09-17T12:53:17.521464Z",
  "parser_version": "plain-txt-v1",
  "tags": [],
  "layout_tags": [],
  "used_ocr": false,
  "parse_chunk_duration_ms": 1,
  "heading_path": [],
  "headings": [],
  "line_range": [
    281,
    307
  ],
  "chunk_duration_ms": null
}