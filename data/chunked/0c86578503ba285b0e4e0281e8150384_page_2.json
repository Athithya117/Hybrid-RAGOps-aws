{
  "document_id": "0c86578503ba285b0e4e0281e8150384",
  "chunk_id": "0c86578503ba285b0e4e0281e8150384_page_2",
  "chunk_type": "page",
  "text": "proposeHyFedRAG,aunifiedandefficientfederatedRAG hancing cross-source integration and reasoning. However,\n\nframework for hybrid data structures. Our framework of- UniHGKR is primarily designed for a centralized architec-\n\nfers a scalable and privacy-compliant solution for RAG tureanddoesnotaddressthechallengesofefficienthetero-\n\nover structural-heterogeneous data, unlocking the potential geneous retrieval in distributed, privacy-sensitive environ-\n\nofLLMsinsensitiveanddiversedataenvironments.Ourkey ments. Similarly, Christmann and Weikum (2024) explores\n\ncontributionsareasfollows: the use of retrieval-augmented generation to boost the ac-\n\ncuracy and robustness of QA systems when handling un-\n\nFederated Hybrid RAG Architecture.\n\nstructuredinputssuchastablesandimages,yetitofferslim-\n\nsign an edge–cloud collaborative pipeline based on\n\nited insight into the fusion of multi-source retrieval results\n\nFlower(Beutel et al. 2020), facilitating seamless query-\n\nor into mechanisms for preserving privacy during process-\n\ning over structured SQL databases, semi-structured\n\ning.Theseapproachesabovealltendtobuildasingle,unified\n\nknowledge graphs, and unstructured text corpora.\n\nheterogeneous-dataretriever—overlookingtheuniquechar-\n\nEdge-side LLMs handle data conversion into unified\n\nacteristics of each data format—and they also expose pri-\n\nand privacy-conscious formats, while cloud-side LLMs\n\nvate information when data sources communicate with one\n\naggregate and reason over these representations to\n\nanother.\n\ngeneratecomprehensiveoutputs.\n\nIndistributedsettings—especiallywithinfederatedlearn-\n\nPrivacy-Aware Summarization.\n\n2. We incorporate effi-\n\ning and multimodal systems—efficient caching and the re-\n\ncient local retrieval modules combined with privacy-\n\nduction of redundant computations are crucial for main-\n\npreserving LLMs and introduce three anonymization\n\ntaining high performance. For example,Wu et al. (2024)\n\nmechanisms, Presidio-based masking (Microsoft 2021),\n\nintroduces a hierarchical cache of model outputs and\n\nEraser4RAG(Wangetal.2025b),andTenSEAL-enabled\n\nfeature embeddings at client and server levels, enabling\n\ntensorencryption(Benaissaetal.2021).,allowingclients\n\npersonalized on-device inference while minimizing com-\n\nto generate de-identified yet semantically meaningful\n\nmunication overhead. Meanwhile,Balasubramanian et al.\n\nsummariesforcross-institutionglobalreasoning.\n\n(2021) demonstrates how learned caching layers can pre-\n\nThree-Tier Caching Mechanism.\n\n3. To accelerate infer-\n\ndict and reuse frequently accessed intermediate represen-\n\nenceandreducecommunicationoverhead,weimplement\n\ntations to speed up inference on a single node. How-\n\ncaching at (i) direct Summary Features, (ii) one-Hop\n\never, FedCache focuses on classification and personaliza-\n\nNeighbor Prefetch, and (iii) cold-Start + Two-Hop\n\ntion in edge environments without addressing multimodal\n\nNeighbor Prefetch, achieving up to 80% reduction in\n\nretrieval,andLearnedCachestargetsingle-nodedeployment\n\nend-to-endlatency.\n\nwithout consideration for privacy or heterogeneity across\n\n4. Comprehensive Evaluation. We conduct extensive ex-\n\nclients.Buildingontheseadvances,HyFedRAGimplements\n\nperiments on both synthetic and real-world healthcare\n\na three-tier caching acceleration mechanism—caching lo-\n\nbenchmarks.ResultsshowthatHyFedRAGconsistently\n\ncal summary features, summary-to-LLM-input transforma-\n\noutperforms centralized RAG and existing federated\n\ntions, and high-frequency inference outputs—to minimize\n\nbaselines in retrieval accuracy, generation consistency,\n\ncross-clientcommunicationlatencyandcomputationalbur-\n\nandsystemthroughput.\n\nden,therebyenhancingbothsystemthroughputandrespon-\n\nsiveness.\n\n2 RelatedWorks\n\n3 Methodology\n\nIn the domain of heterogeneous knowledge retrieval, sev-\n\neral studies have sought to integrate information from dis-\n\nIn this section, we will introduce the overall framework of\n\nparate data sources. However, existing approaches exhibit\n\nHyFedRAG, the functional design of various modules, and\n\nnotablelimitations.Forinstance,Lietal.(2021)andKosti´\n\nthedefinitionoftheretrievalscenarios.\n\nRisch,andM¨ oller(2021)constructseparateretrievalindices\n\nfor each data modality—text, tabular data, and knowledge\n\n3.1 OverviewofHyFedRAG\n\ngraphs—andperformretrievalindependentlyoneachindex,\n\nHyFedRAGisanend-to-endfederatedretrievalandgenera-\n\na strategy that fails to support privacy-preserving retrieval\n\ntion framework designed for cross-client, multi-source het-\n\nacross different data sources. By contrast, the UDT-QA\n\nerogeneousdata. Itsarchitecture comprisesthree hierarchi-\n\nframeworkproposedbyMaetal.(2022)introducesamulti-\n\ncallayers:theClientLayer,theMiddlewareLayer,andthe\n\nmodalpipelinecomprisingagenerator,retriever,andreader:\n\nCentralServerLayer.Weimplementthefederatedworkflow\n\na fine-tuned generative model first converts heterogeneous\n\nusing the Flower framework, storing each data modality in\n\ninputs into a homogeneous textual representation, which is\n\nthefollowingsystems:\n\ntheningestedbyadownstreamreader.Althoughthismethod\n\nleverages multiple heterogeneous data sources, its retrieval\n\nUnstructuredText:FAISSvectordatabase\n\nisfocusedontheinputtext—hinderinggeneralization—and\n\nStructuredData:ClientsideSQLdatabase\n\nit likewise fails to support privacy preservation across data\n\n• KnowledgeGraphs:Neo4jgraphdatabase\n\nsources. (Huang et al. (2019); Lin et al. (2023)). The Uni-\n\nHGKR framework (Min et al. 2025) addresses this gap by\n\nproviding an instruction-aware retrieval interface that uni- Client Layer At the client layer, HyFedRAG performs\n\nfies text, knowledge graphs, and tables, substantially en- multimodal retrieval and preliminary summary generation",
  "token_count": 1295,
  "embedding": null,
  "file_type": "application/pdf",
  "source_url": "s3://e2e-rag-system-42/data/raw/pdfs/graph_rag_sep_2025.pdf",
  "page_number": 2,
  "slide_range": null,
  "row_range": null,
  "token_range": [
    0,
    1294
  ],
  "audio_range": null,
  "timestamp": "2025-09-17T12:52:22.353003Z",
  "parser_version": null,
  "tags": null,
  "layout_tags": [
    "page"
  ],
  "used_ocr": false,
  "parse_chunk_duration_ms": 434,
  "heading_path": [],
  "headings": [],
  "line_range": null,
  "chunk_duration_ms": null
}