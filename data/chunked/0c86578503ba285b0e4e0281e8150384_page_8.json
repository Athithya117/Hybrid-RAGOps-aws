{
  "document_id": "0c86578503ba285b0e4e0281e8150384",
  "chunk_id": "0c86578503ba285b0e4e0281e8150384_page_8",
  "chunk_type": "page",
  "text": "References\n\nB. 2021. Dual Reader-Parser on Hybrid Textual and Tab-\n\nular Evidence for Open Domain Question Answering. In\n\nAleman, F. L.; Almeida, D.; Altenschmidt, J.; Altman, S.;\n\nProceedingsofthe59thAnnualMeetingoftheAssociation\n\narXiv\n\nAnadkat, S.; et al. 2023. Gpt-4 technical report.\n\nfor Computational Linguistics and the 11th International\n\npreprintarXiv:2303.08774.\n\nJointConferenceonNaturalLanguageProcessing(Volume\n\nBalasubramanian, A.; Kumar, A.; Liu, Y.; Cao, H.;\n\n1:LongPapers),4078–4088.\n\nVenkataraman, S.; and Akella, A. 2021. Accelerating\n\narXiv preprint\n\ndeep learning inference via learned caches.\n\nLi, C.; Liu, Z.; Xiao, S.; and Shao, Y. 2023. Making large\n\narXiv:2101.07344.\n\nlanguage models a better foundation for dense retrieval.\n\narXivpreprintarXiv:2312.15503.\n\nBehnamGhader, P.; Adlakha, V.; Mosbach, M.; Bahdanau,\n\nD.;Chapados,N.;andReddy,S.2024. Llm2vec:Largelan-\n\nLin, W.; Blloshmi, R.; Byrne, B.; de Gispert, A.; and Igle-\n\nguage models are secretly powerful text encoders.\n\nsias,G.2023. Aninnertableretrieverforrobusttableques-\n\npreprintarXiv:2404.05961.\n\nInProceedingsofthe61stAnnualMeeting\n\ntionanswering.\n\nBenaissa, A.; Retiat, B.; Cebere, B.; and Belfedhal, A. E.\n\noftheAssociationforComputationalLinguistics(Volume1:\n\n2021. Tenseal: A library for encrypted tensor oper-\n\nLongPapers),9909–9926.\n\nations using homomorphic encryption.\n\narXiv:2104.03152.\n\n2023. G-Eval:NLGEvaluationusingGpt-4withBetterHu-\n\nInProceedingsofthe2023Conferenceon\n\nmanAlignment.\n\nEmpiricalMethodsinNaturalLanguageProcessing,2511–\n\nDe Gusm˜ ao, P. P. B.; et al. 2020. Flower: A friendly\n\n2522.\n\nfederated learning research framework.\n\narXiv:2007.14390.\n\nOpenDomainQuestionAnsweringwithAUnifiedKnowl-\n\nChristmann,P.;andWeikum,G.2024. Rag-basedquestion\n\nInProceedingsofthe60thAnnualMeeting\n\nedgeInterface.\n\narXivpreprint\n\nansweringoverheterogeneousdataandtext.\n\narXiv:2412.07420.\n\nLongPapers),1605–1620.\n\nDubey,A.;Jauhri,A.;Pandey,A.;Kadian,A.;Al-Dahle,A.;\n\nMicrosoft. 2021. Presidio: A Privacy-Preserving PII De-\n\ntection and Anonymization Toolkit. https://github.com/\n\narXiv e-prints,\n\net al. 2024. The llama 3 herd of models.\n\nmicrosoft/presidio. Accessed:2025-08-01.\n\narXiv–2407.\n\nMin,D.;Xu,Z.;Qi,G.;Huang,L.;andYou,C.2025. Uni-\n\nHerzig, J.; Mueller, T.; Krichene, S.; and Eisenschlos, J.\n\nHGKR: Unified Instruction-aware Heterogeneous Knowl-\n\n2021. Open Domain Question Answering over Tables via\n\nInProceedingsofthe2025Conferenceof\n\nedgeRetrievers.\n\nInProceedingsofthe2021Conferenceof\n\nDenseRetrieval.\n\nthe Nations of theAmericas Chapter of the Association for\n\ntheNorthAmericanChapteroftheAssociationforCompu-\n\nComputationalLinguistics:HumanLanguageTechnologies\n\ntational Linguistics: Human Language Technologies,\n\n(Volume1:LongPapers),4577–4594.\n\nSchick,T.;Dwivedi-Yu,J.;Dess`ı,R.;Raileanu,R.;Lomeli,\n\nQuestion decomposition tree for answering complex ques-\n\nM.; Hambro, E.; Zettlemoyer, L.; Cancedda, N.; and\n\nProceedings of the AAAI\n\ntions over knowledge bases. In\n\nScialom,T.2023. Toolformer:Languagemodelscanteach\n\nConference on Artificial Intelligence,\n\nvolume 37, 12924–\n\nAdvances in Neural Information\n\nthemselves to use tools.\n\n12932.\n\nProcessingSystems,36:68539–68551.\n\nHuang, X.; Zhang, J.; Li, D.; and Li, P. 2019. Knowledge\n\nSeo,M.2024. REPLUG:Retrieval-AugmentedBlack-Box\n\ngraphembeddingbasedquestionanswering.InProceedings\n\nNAACL 2024.\n\nLanguage Models. In Association for Com-\n\nofthetwelfthACMinternationalconferenceonwebsearch\n\nputationalLinguistics(ACL).\n\nanddatamining,105–113.\n\nTeam,G.;Riviere,M.;Pathak,S.;Sessa,P.G.;Hardin,C.;\n\nBhupatiraju, S.; Hussenot, L.; Mesnard, T.; Shahriari, B.;\n\nWilbur, W. J.; and Lu, Z. 2023. Medcpt: Contrastive pre-\n\ne,A.;etal.2024. Gemma2:Improvingopenlanguage\n\ntrainedtransformerswithlarge-scalepubmedsearchlogsfor\n\nmodelsatapracticalsize.arXivpreprintarXiv:2408.00118.\n\nBioinformatics,\n\nzero-shotbiomedicalinformationretrieval.\n\n39(11):btad651.\n\nZheng, Z. 2025a. MaFeRw: Query rewriting with multi-\n\naspect feedbacks for retrieval-augmented large language\n\nFaloutsos, C.; Rangwala, H.; and Karypis, G. 2024.\n\nProceedings of the AAAI Conference on Artifi-\n\nmodels. In\n\nOpentab:Advancinglargelanguagemodelsasopen-domain\n\ncialIntelligence,volume39,25434–25442.\n\narXivpreprintarXiv:2402.14361.\n\ntablereasoners.\n\nKosti´ c,B.;Risch,J.;andM¨ oller,T.2021. Multi-modalRe- Wang,Y.;Zhang,H.;Pang,L.;Tong,Y.;Guo,B.;Zheng,H.;\n\ntrieval of Tables and Texts Using Tri-encoder Models. In andZheng,Z.2025b. LearningtoErasePrivateKnowledge\n\nProceedings of the 3rd Workshop on Machine Reading for\n\nfrom Multi-Documents for Retrieval-Augmented Large\n\nQuestionAnswering,82–91. arXivpreprintarXiv:2504.09910.\n\nLanguageModels.",
  "token_count": 1508,
  "embedding": null,
  "file_type": "application/pdf",
  "source_url": "s3://e2e-rag-system-42/data/raw/pdfs/graph_rag_sep_2025.pdf",
  "page_number": 8,
  "slide_range": null,
  "row_range": null,
  "token_range": [
    0,
    1507
  ],
  "audio_range": null,
  "timestamp": "2025-09-17T12:52:49.957595Z",
  "parser_version": null,
  "tags": null,
  "layout_tags": [
    "page"
  ],
  "used_ocr": false,
  "parse_chunk_duration_ms": 471,
  "heading_path": [],
  "headings": [],
  "line_range": null,
  "chunk_duration_ms": null
}